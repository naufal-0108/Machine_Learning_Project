{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from langchain.tools import StructuredTool\n",
    "from typing import List, Dict, Optional, Any, Literal\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from together import Together\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_collection = {\n",
    "    \"title\": \"Ramen Noodles Recipe and Steak Cooking Guide\",\n",
    "    \"content\": \"\"\"**Title:** Ramen Noodles Recipe and Steak Cooking Guide\n",
    "**Introduction:**\n",
    "Ramen noodles are a popular Japanese dish that can be customized to suit various tastes. This recipe provides a basic guide on how to prepare a delicious and flavorful ramen noodle dish. Additionally, we've included a guide on how to cook a perfect steak.\n",
    "\n",
    "**Ramen Noodles Recipe:**\n",
    "**Introduction:**\n",
    "Ramen noodles are a popular Japanese dish that can be customized to suit various tastes. This recipe provides a basic guide on how to prepare a delicious and flavorful ramen noodle dish.\n",
    "\n",
    "**Ingredients:**\n",
    "- 1 package of ramen noodles\n",
    "- 2 cups of water\n",
    "- 1 tablespoon of vegetable oil\n",
    "- 1 small onion, diced\n",
    "- 2 cloves of garlic, minced\n",
    "- 1 cup of mixed vegetables (e.g., carrots, green onions, mushrooms)\n",
    "- 1 teaspoon of soy sauce\n",
    "- 1 teaspoon of sesame oil\n",
    "- Salt and pepper to taste\n",
    "- Optional: boiled egg, sliced pork, or green onions for topping\n",
    "\n",
    "**Instructions:**\n",
    "1. **Prepare the Broth:** Bring the water to a boil in a large pot.\n",
    "2. **Cook the Noodles:** Add the ramen noodles and cook according to the package instructions. Typically, this involves boiling for 2-3 minutes or until the noodles are slightly undercooked.\n",
    "3. **Sauté the Aromatics:** In a separate pan, heat the vegetable oil over medium heat. Add the diced onion and minced garlic and sauté until softened, about 3-4 minutes.\n",
    "4. **Add Mixed Vegetables:** Add the mixed vegetables to the pan and cook until they're tender, about 4-5 minutes.\n",
    "5. **Combine and Season:** Combine the cooked noodles, vegetable mixture, soy sauce, and sesame oil in a bowl. Season with salt and pepper to taste.\n",
    "6. **Serve:** Serve hot, with optional toppings such as boiled egg, sliced pork, or green onions.\n",
    "\n",
    "**Tips and Variations:**\n",
    "- For added protein, consider adding cooked chicken, beef, or tofu.\n",
    "- Experiment with different seasonings, such as chili flakes or grated ginger, to give your ramen a unique flavor.\n",
    "- Use low-sodium broth or reduce the amount of soy sauce to decrease the dish's salt content.\n",
    "\n",
    "**Steak Cooking Guide:**\n",
    "**Introduction:**\n",
    "Cooking a perfect steak can be a challenge, but with the right techniques and ingredients, you can achieve a delicious and tender steak.\n",
    "\n",
    "**Ingredients:**\n",
    "- 1-2 steaks (depending on size and preference)\n",
    "- 2 tablespoons of olive oil\n",
    "- 1 teaspoon of salt\n",
    "- 1/2 teaspoon of black pepper\n",
    "- 1/2 teaspoon of garlic powder (optional)\n",
    "- 1/2 teaspoon of paprika (optional)\n",
    "\n",
    "**Instructions:**\n",
    "1. **Prepare the Steak:** Bring the steak to room temperature by leaving it out for 30 minutes to 1 hour before cooking.\n",
    "2. **Season the Steak:** Rub the steak with olive oil, salt, black pepper, garlic powder, and paprika (if using).\n",
    "3. **Heat the Pan:** Heat a skillet or grill pan over high heat. Add a small amount of oil to the pan and swirl it around.\n",
    "4. **Sear the Steak:** Add the steak to the pan and sear for 2-3 minutes per side, depending on the thickness of the steak and your desired level of doneness.\n",
    "5. **Finish Cooking:** After searing the steak, reduce the heat to medium-low and continue cooking to your desired level of doneness.\n",
    "6. **Let it Rest:** Once the steak is cooked, remove it from the heat and let it rest for 5-10 minutes before slicing and serving.\n",
    "\n",
    "**Tips and Variations:**\n",
    "- Use a meat thermometer to ensure the steak is cooked to your desired level of doneness.\n",
    "- Let the steak rest for a few minutes before slicing to allow the juices to redistribute.\n",
    "- Experiment with different seasonings and marinades to give your steak a unique flavor.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_api_key = os.environ.get(\"TOGETHER_API_KEY\")\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "model = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    "max_tokens = 1024\n",
    "temperature = 0.6\n",
    "client = Together(api_key=together_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41866a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "refiner_agent_format = \"\"\"{\n",
    "    \"agent\": \"Refiner Agent\",\n",
    "    \"content\": \"content (keep formating)\"\n",
    "}\n",
    "\"\"\"\n",
    "refiner_agent_format_resp =  \"\"\"{\n",
    "    \"sender\": \"Refiner Agent\",\n",
    "    \"content\": \"content (keep formating)\"\n",
    "}\"\"\"\n",
    "\n",
    "database_agent_format_retrieve = \"\"\"{\n",
    "    \"agent\": \"Database Agent\",\n",
    "    \"task\": \"retrieve\",\n",
    "    \"title\": \"Title note\" or \"None\"\n",
    "}\"\"\"\n",
    "\n",
    "database_agent_format_save = \"\"\"{\n",
    "    \"agent\": \"Database Agent\",\n",
    "    \"task\": \"save\",\n",
    "    \"title\": \"Title note\",\n",
    "    \"content\": \"Finalized Content (keep formating)\"\n",
    "}\"\"\"\n",
    "\n",
    "database_agent_format_deletion = \"\"\"{\n",
    "    \"agent\": \"Database Agent\",\n",
    "    \"task\": \"delete\",\n",
    "    \"title\": \"Title note\"\n",
    "}\"\"\"\n",
    "\n",
    "database_agent_format_input = \"\"\"\n",
    "    \"agent\": \"Database Agent\",\n",
    "    \"task\": (\"save\" or \"retrieve\" or \"delete\"),\n",
    "    \"title\": \"Title note\" or \"None\"\n",
    "    \"content\": \"Content note\" or \"None\"\n",
    "\"\"\"\n",
    "database_agent_format_resp = \"\"\"\n",
    "    \"task\": (\"save\" or \"retrieve\" or \"delete\"),\n",
    "    \"title\": \"Title note\" or \"None\",\n",
    "    \"content\": \"Content note\" or \"None\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinerSchema(BaseModel):\n",
    "    refined_content: str\n",
    "    \n",
    "class EvaluatorSchema(BaseModel):\n",
    "    status: Literal[\"PASS\", \"NEED REVISION\"]\n",
    "    revision: str\n",
    "\n",
    "class DatabaseSchema(BaseModel):\n",
    "    task: str\n",
    "    title: Optional[str]\n",
    "    content: Optional[str]\n",
    "    \n",
    "manager_prompt = \"\"\"\n",
    "You are Naufal's personal assistant and the manager of two agents: the **Refining Agent** and the **Database Agent**. Your responsibilities are:\n",
    "\n",
    "### Roles:\n",
    "1. **Personal Assistant**  \n",
    "   Act as a helpful, engaging companion. Proactively assist Naufal in creating, designing, or taking notes on topics of interest.\n",
    "\n",
    "2. **Agent Manager**  \n",
    "   Coordinate two specialized agents:\n",
    "   - **Refining Agent**: Improves note content for clarity and informativeness.\n",
    "   - **Database Agent**: Stores finalized notes and retrieves them when needed.\n",
    "\n",
    "### Workflow:\n",
    "\n",
    "**1. Initiation**  \n",
    "Start as Naufal’s assistant. Suggest taking a note if relevant to the conversation.\n",
    "\n",
    "**2. Note Creation & Management**\n",
    "- **If Naufal provides content at first**:\n",
    "  - Recompile it again as a note with contents as same as contents that naufal provided.\n",
    "  - Ask if he wants it refined (no JSON schema shown when you ask).\n",
    "    - If **yes**, respond **only** in JSON: `{refiner_agent_format}`\n",
    "    - If **no**, resume the conversation.\n",
    "- **If no content is provided**:\n",
    "  - Suggest relevant topics.\n",
    "  - Ask if naufal wants to create a note now or later.\n",
    "    -if **yes**, show the draft to naufal first and inform him he can modify this draft throughout chat.\n",
    "    -if **no**, continue conversation and recommend him to create a note later on.\n",
    "  - if Naufal wants to refine the created note. (no JSON schema shown when you ask).\n",
    "    - If **yes**, respond **only** in JSON: `{refiner_agent_format}`\n",
    "    - If **no**, continue the conversation.\n",
    "\n",
    "**3. Note Refinement**\n",
    "- You’ll receive refined content in format: `{refiner_agent_format_resp}`\n",
    "- Present it to Naufal and ask for feedback:\n",
    "  - If **satisfied**, continue the conversation and memorize previous the refined content.\n",
    "  - If **not satisfied**, respond **only** in JSON: `{refiner_agent_format}`\n",
    "\n",
    "**4. Previous Created Notes**\n",
    "- If naufal asks you to show him either the draft or the refined notes, check your previous conversation first then responds to naufal back. Do not call any agents/tools.\n",
    "\n",
    "**5. Note Saving to Database**\n",
    "-If naufal does not show an action that he wants to save the note, do not ask him 'want to save the not or not'.\n",
    "-If you recommend naufal to save the note or not, just ask the question without showing json format for the database agent.\n",
    "    - If naufal says **yes**, Respond **only** in JSON: `{database_agent_format_save}`. Once you received saving successfull notification from Database Agent, inform the message to naufal.\n",
    "    - If **no**, continue the conversation and memorize the refined content.\n",
    "-If Naufal asks to save the created note:\n",
    "  - Respond **only** in JSON: `{database_agent_format_save}`.\n",
    "  - Once you received saving successfull notification from Database Agent, inform the message to naufal.\n",
    "\n",
    "**6. Note Retrieval from Database**\n",
    "- When Naufal asks to retrieve notes that are saved in database:\n",
    "  - Respond **only** in JSON: `{database_agent_format_retrieve}`\n",
    "  - Once a list of saved notes is returned, ask which one he wants.\n",
    "  - Then respond **only** in JSON: `{database_agent_format_retrieve}` again.\"\"\"\n",
    "\n",
    "refiner_prompt = \"\"\"\n",
    "You are a competent refiner agent. You work with: your **manager** who is the main & frontline agent for Naufal and your other partner is **Database** agent who will save & retrive notes.\n",
    "Your only main job/task is to refine the note's content that your manager orders you to do. You will be provided with 3 context: a task, a previous generation, and a revision. \n",
    "task is the order that your manager gives, previous generation is your previous refined content, and revision is the feedback from evaluator that you need to fix it. if the & previous generation & revision are none, that indicates it is the first time of the step.\n",
    "You dont need to think very hard, just do it as best & fast as you can since your response will be evaluated by an evaluator AI later. You dont need to call the evaluator AI yourself, it will be called by the system.\n",
    "Reflect to the evaluator's revision and improve your answer.\n",
    "\n",
    "task:\n",
    "\n",
    "Please refine this content:\n",
    "\n",
    "{task}\n",
    "\n",
    "previous generation:\n",
    "\n",
    "{previous_generation}\n",
    "\n",
    "revision:\n",
    "\n",
    "{revision}\n",
    "\n",
    "Only output JSON with the following schema:\n",
    "\n",
    "{schema}\n",
    "\"\"\"\n",
    "\n",
    "evaluator_prompt = \"\"\"\n",
    "You are a competent evaluator. Your task is to assess the quality of a `previous_generation` provided in response to a specific `task` by a refiner agent who is naufal personal agent.\n",
    "Please provide a detailed revision to improve the `previous_generation`. Your evaluation will focus on the following aspects:\n",
    "\n",
    "**Evaluation Criteria:**\n",
    "Carefully evaluate the `previous_generation` based on the following:\n",
    "1.  **Structure & Clarity:** Is it well-organized, easy to understand, and logically structured?\n",
    "2.  **Adding more nuance** Is it the content added some nuance to make it look more expressive?\n",
    "2.  **Conciseness:** Is it to the point, without unnecessary verbosity?\n",
    "3.  **Formatting:** Does the answer use formatting (e.g., bullet points, bolding, lists) effectively and appropriately?\n",
    "4.  **Word Choice & Tone:** Is the language precise and suitable?\n",
    "\n",
    "Only output the evaluation criteria with checker for every list above (complete or not) so that the refiner agent will know where to fix it for the revision.\n",
    "if all the evaluation criteria are marked complete, set status to \"PASS\" else \"NEED REVISION\".\n",
    "\n",
    "previous generation:\n",
    "\n",
    "{previous_generation}\n",
    "\n",
    "Decide if the content is \"PASS\" or \"NEED REVISION\", Only output JSON with the following schema:\n",
    "\n",
    "{schema}\n",
    "\"\"\"\n",
    "\n",
    "database_prompt= \"\"\"\n",
    "You are a smart & competence database agent who works with: your **manager** who is the main & frontline agent for Naufal and your other partner is **Refiner** agent who will refine naufal's created note.\n",
    "Your tasks will be saving & retrieving document from NoSQL (MongoDB) database. Your manager will give the order to you with this format: {manager_format}. 'Agent' means your name, 'task' means your task to save or retrive (task should be only either save or retrive not both),\n",
    "'title' means title of the note (Optional), 'content' means content of the note (Optional). Pay close attention to the manager's order before answering!\n",
    "\n",
    "Manager's order:\n",
    "\n",
    "{task}\n",
    "\n",
    "Only output in JSON format with following schema:\n",
    "\n",
    "{db_schema} \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_prompt = \"\"\"\n",
    "You are Naufal's personal assistant and the manager of two agents: the **Refining Agent** and the **Database Agent**. Your responsibilities are:\n",
    "\n",
    "### Roles:\n",
    "1. **Personal Assistant**  \n",
    "   Act as a helpful, engaging companion. Proactively assist Naufal in creating, designing, or taking notes on topics of interest.\n",
    "\n",
    "2. **Agent Manager**  \n",
    "   Coordinate two specialized agents:\n",
    "   - **Refining Agent**: Improves note content for clarity and informativeness.\n",
    "   - **Database Agent**: Stores finalized notes and retrieves them when needed.\n",
    "\n",
    "### Workflow:\n",
    "\n",
    "**1. Initiation**  \n",
    "Start as Naufal’s assistant. Suggest taking a note if relevant to the conversation.\n",
    "\n",
    "**2. Note Creation & Management**\n",
    "- **If Naufal provides content at first**:\n",
    "  - Recompile it again as a note with contents as same as contents that naufal provided.\n",
    "  - Ask if he wants it refined (no JSON schema shown when you ask).\n",
    "    - If **yes**, respond **only** in JSON: `{refiner_agent_format}`\n",
    "    - If **no**, resume the conversation.\n",
    "- **If no content is provided**:\n",
    "  - Suggest relevant topics.\n",
    "  - Ask if naufal wants to create a note now or later.\n",
    "    -if **yes**, show the draft to naufal first and inform him he can modify this draft throughout chat.\n",
    "    -if **no**, continue conversation and recommend him to create a note later on.\n",
    "  - if Naufal wants to refine the created note. (no JSON schema shown when you ask).\n",
    "    - If **yes**, respond **only** in JSON: `{refiner_agent_format}`\n",
    "    - If **no**, continue the conversation.\n",
    "\n",
    "**3. Note Refinement**\n",
    "- You’ll receive refined content in format: `{refiner_agent_format_resp}`\n",
    "- Present it to Naufal and ask for feedback:\n",
    "  - If **satisfied**, continue the conversation and memorize previous the refined content.\n",
    "  - If **not satisfied**, respond **only** in JSON: `{refiner_agent_format}`\n",
    "\n",
    "**4. Previous Created Notes**\n",
    "- If naufal asks you to show him either the draft or the refined notes, check your previous conversation first then responds to naufal back. Do not call any agents/tools.\n",
    "\n",
    "**5. Note Saving to Database**\n",
    "-Either if Naufal wants to save the note or you recommend naufal to save the note or not, just answer/ask the question without showing json format for the database agent.\n",
    "    - If naufal says **yes**, Respond **only** in JSON: `{database_agent_format_save}`. Once you received notification from Database Agent, inform the message to naufal.\n",
    "    - If **no**, continue the conversation and memorize the refined content.\n",
    "\n",
    "**6. Note Retrieval from Database**\n",
    "- When Naufal asks to retrieve notes that are saved in database:\n",
    "  - Respond **only** in JSON: `{database_agent_format_retrieve}`\n",
    "  - Once a list of saved notes is returned, ask which one he wants.\n",
    "  \n",
    "**7. Note Deletion to Database**  \n",
    "- Do **not** recommend deletion unless Naufal explicitly asks for it.  \n",
    "- If Naufal asks to delete a note, first check your chat history (internally) to see if you already have a full list of saved-note titles:  \n",
    "  - **If you do _not_ have a full list**, respond _only_ with this JSON (no extra text before or after):\n",
    "    {database_agent_format_retrieve}\n",
    "  - **If you _do_ have a full list** and Naufal has specified one of those titles, respond _only_ with this JSON (no extra text before or after):\n",
    "    {database_agent_format_deletion}\n",
    "- **IMPORTANT:** Under _all_ circumstances in this step, the model’s output **must be exactly** the JSON object and **nothing else**—no apologies, no clarifications, no surrounding prose.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c872e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_prompt = \"\"\"\n",
    "You are Naufal’s personal assistant and the manager of two agents:\n",
    "  • Refining Agent — polishes note content  \n",
    "  • Database Agent — saves and retrieves notes  \n",
    "\n",
    "ROLES\n",
    "1. Personal Assistant\n",
    "   – Engage proactively: suggest taking notes, design or discuss topics.\n",
    "2. Agent Manager\n",
    "   – Route tasks to the Refining or Database Agent using the prescribed JSON schemas.\n",
    "\n",
    "WORKFLOW\n",
    "\n",
    "1. NOTE CREATION  \n",
    "   • If Naufal supplies content:\n",
    "     1. Wrap it in a draft note (no JSON shown).  \n",
    "     2. Ask “Refine this note?” (no JSON shown).  \n",
    "        – Yes → output exactly `{refiner_agent_format}`  \n",
    "        – No  → resume conversation.\n",
    "   • If no content:\n",
    "     1. Propose topics.  \n",
    "     2. Ask Naufal to create a note now or later.  \n",
    "        – Yes → show draft, allow edits; recommend “Refine?” as above.  \n",
    "        – No  → continue chat; remind later.\n",
    "\n",
    "2. NOTE REFINEMENT  \n",
    "   • After receiving `{refiner_agent_format_resp}`, present refined text and ask satisfied or not.  \n",
    "     – Yes → confirm and remember it.  \n",
    "     – No  → output exactly `{refiner_agent_format}` again.\n",
    "\n",
    "3. NOTE SAVING  \n",
    "   • When Naufal agrees to save:\n",
    "     – Output exactly `{database_agent_format_save}`  \n",
    "     – After Database Agent confirms, notify Naufal.  \n",
    "   • If he declines, remember content and continue.\n",
    "\n",
    "4. NOTE RETRIEVAL  \n",
    "   • On retrieval request → output exactly `{database_agent_format_retrieve}`  \n",
    "   • When list returns → ask which title to act on.\n",
    "\n",
    "5. NOTE DELETION  \n",
    "   • Never suggest deletion. Only if requested:\n",
    "     1. If no title list exists → output exactly `{database_agent_format_retrieve}`. Emit only the JSON object, no extra text.\n",
    "     2. If list exists and title provided → output exactly `{database_agent_format_deletion}`.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def refiner_agent(task: Optional[str], previous_generation: Optional[str], revision: Optional[str], history: List, schema:Optional[Any]) -> str:\n",
    "    \"\"\"\n",
    "    Refine a content based on the task, previous generation, revision\n",
    "    \"\"\"\n",
    "    prompt = refiner_prompt.format(\n",
    "        task=task,\n",
    "        previous_generation=previous_generation,\n",
    "        revision=revision,\n",
    "        schema=schema.model_json_schema()\n",
    "    )\n",
    "\n",
    "    history += [{\"role\": \"system\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(model=model, temperature=temperature, max_tokens=max_tokens, messages=history,\n",
    "                                              response_format={\"type\": \"json_object\",\"schema\": schema.model_json_schema(),})\n",
    "\n",
    "    return response.choices[0].message.content, history\n",
    "\n",
    "def evaluator_agent(previous_answer: Optional[str], schema: Optional[Any], history: List) -> str:\n",
    "\n",
    "    \n",
    "\n",
    "    history += [{\"role\": \"system\", \"content\": evaluator_prompt.format(previous_generation=previous_answer, schema=schema.model_json_schema())}]\n",
    "\n",
    "    response = client.chat.completions.create(model=model, temperature=temperature, messages=history, max_tokens=max_tokens,\n",
    "                                              response_format={\"type\": \"json_object\",\"schema\": schema.model_json_schema(),})\n",
    "    return response.choices[0].message.content, history\n",
    "\n",
    "\n",
    "def database_agent(task: str, schema: Optional[Any]):\n",
    "\n",
    "    message = [{\"role\": \"system\", \"content\": database_prompt.format(task=task, manager_format=database_agent_format_input, db_schema=database_agent_format_resp)}]\n",
    "\n",
    "    response = client.chat.completions.create(model=model, temperature=temperature, max_tokens=max_tokens, messages=message,\n",
    "                                              response_format={\"type\": \"json_object\",\"schema\": schema.model_json_schema(),})\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9357a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = [{\"role\": \"system\", \"content\": manager_prompt.format(refiner_agent_format=refiner_agent_format, refiner_agent_format_resp=refiner_agent_format_resp,\n",
    "                                                                       database_agent_format_save=database_agent_format_save, database_agent_format_retrieve=database_agent_format_retrieve,\n",
    "                                                                       database_agent_format_deletion=database_agent_format_deletion)}]\n",
    "\n",
    "while True:\n",
    "\n",
    "    user_input = input_preprocessing(input(\"Ask anything:\"))\n",
    "\n",
    "    if user_input in ['exit', 'q']:\n",
    "        break\n",
    "\n",
    "    print(\"=======================HUMAN MESSAGE============================\")\n",
    "    print(user_input)\n",
    "    message_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    print(\"========================AI MESSAGE==============================\")\n",
    "\n",
    "    llm_response_complete = \"\"\n",
    "\n",
    "    for chunk in client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=temperature, stream=True, messages=message_history):\n",
    "\n",
    "        response = chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "        print(response, end=\"\", flush=True)\n",
    "        llm_response_complete += response\n",
    "    \n",
    "    message_history.append({\"role\": \"assistant\", \"content\": llm_response_complete})\n",
    "\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        json_response = json.loads(llm_response_complete, strict=False)\n",
    "        agent = True\n",
    "\n",
    "    except:\n",
    "        agent = False\n",
    "\n",
    "\n",
    "    if agent:\n",
    "\n",
    "        agent_name = json_response.get(\"agent\").lower().strip()\n",
    "        \n",
    "        if agent_name == \"refiner agent\":\n",
    "            json_response = json.loads(llm_response_complete, strict=False)\n",
    "            refine_agent_history = []\n",
    "            evaluator_agent_history = []\n",
    "\n",
    "            print(\"======================System Message============================\")\n",
    "            print(\"Calling Refiner Agent...\")\n",
    "            print(\"======================System Message============================\")\n",
    "            \n",
    "            first_step, history = refiner_agent(task=json_response.get(\"content\"), history=refine_agent_history, previous_generation=None, revision=None, schema=RefinerSchema)\n",
    "            prev_step = first_step\n",
    "\n",
    "            for num_ref in tqdm(range(5), desc=\"Refining content...\", leave=True):\n",
    "                revision, feedback_history = evaluator_agent(\n",
    "                    previous_answer=json.loads(prev_step)['refined_content'],\n",
    "                    schema=EvaluatorSchema,\n",
    "                    history=evaluator_agent_history\n",
    "                )\n",
    "\n",
    "                status = json.loads(revision)[\"status\"]\n",
    "                feedback = json.loads(revision)[\"revision\"]\n",
    "\n",
    "                print(status)\n",
    "\n",
    "                if status == \"PASS\":\n",
    "                    break\n",
    "\n",
    "                prev_step, refined_content_history = refiner_agent(\n",
    "                    task=json_response.get(\"content\"),\n",
    "                    previous_generation=json.loads(prev_step)['refined_content'],\n",
    "                    revision=feedback,\n",
    "                    history=refine_agent_history,\n",
    "                    schema=RefinerSchema\n",
    "                )\n",
    "\n",
    "                refined_content_history.append({\"role\": \"system\", \"content\":json.loads(prev_step)['refined_content']})\n",
    "\n",
    "            refiner_agent_resp = str(dict({\"sender\": \"Refiner_Agent\", \"content\": json.loads(prev_step)['refined_content']}))\n",
    "\n",
    "            message_history.append({\"role\": \"system\", \"content\": refiner_agent_resp})\n",
    "\n",
    "\n",
    "            print(\"======================System Message============================\")\n",
    "            print(\"Sending back to main agent...\")\n",
    "            print(\"========================AI MESSAGE==============================\")\n",
    "\n",
    "            for chunk in client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=temperature, stream=True, messages=message_history):\n",
    "\n",
    "                response = chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "                print(response, end=\"\", flush=True)\n",
    "                llm_response_complete += response\n",
    "\n",
    "            print()\n",
    "\n",
    "        else:\n",
    "            print(\"======================System Message============================\")\n",
    "            print(\"Calling Database Agent...\")\n",
    "            print(\"======================System Message============================\")\n",
    "            db_agent_resp = json.loads(database_agent(task=json_response, schema=DatabaseSchema), strict=False)\n",
    "\n",
    "            print(db_agent_resp, flush=True)\n",
    "\n",
    "            if db_agent_resp.get('task').lower().strip() == \"save\":\n",
    "\n",
    "                title_note = db_agent_resp.get('title').strip()\n",
    "                content_note = db_agent_resp.get('content').strip()\n",
    "\n",
    "                assert (title_note != \"None\") and (content_note != \"None\"), \"Title and content must not be None\"\n",
    "\n",
    "                new_collection = {\"title\": title_note, \"content\": content_note}\n",
    "                status = collections.insert_one(new_collection)\n",
    "\n",
    "                assert status.__getstate__()[-1]['_WriteResult__acknowledged'], \"Fail to write to database\"\n",
    "\n",
    "                feedback_db = {\"role\": \"system\", \"content\": str({\"sender\": \"Database Agent\", \"saving_status\": \"The note has been successfully saved to the database!\"})}\n",
    "                message_history.append(feedback_db)\n",
    "\n",
    "\n",
    "                print(\"======================System Message============================\")\n",
    "                print(\"Sending back to main agent...\")\n",
    "                print(\"========================AI MESSAGE==============================\")\n",
    "\n",
    "                llm_response_complete = \"\"\n",
    "                for chunk in client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=temperature, stream=True, messages=message_history):\n",
    "\n",
    "                    response = chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "                    print(response, end=\"\", flush=True)\n",
    "                    llm_response_complete += response\n",
    "\n",
    "                print()\n",
    "\n",
    "            elif db_agent_resp.get('task').lower().strip() == \"retrieve\":\n",
    "\n",
    "                title_note = db_agent_resp.get('title').strip()\n",
    "\n",
    "                if title_note.lower() == \"none\":\n",
    "                    all_collections = [c.get(\"title\") for c in collections.find({}, {\"_id\": 0, \"title\": 1})]\n",
    "\n",
    "                    feedback_db = {\"role\": \"system\", \"content\": str({\"sender\": \"Database Agent\", \"retreived_all_title_saved_notes\": all_collections})}\n",
    "                    message_history.append(feedback_db)\n",
    "\n",
    "                    print(\"======================System Message============================\")\n",
    "                    print(\"Sending back to main agent...\")\n",
    "                    print(\"========================AI MESSAGE==============================\")\n",
    "\n",
    "                    llm_response_complete = \"\"\n",
    "                    for chunk in client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=temperature, stream=True, messages=message_history):\n",
    "\n",
    "                        response = chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "                        print(response, end=\"\", flush=True)\n",
    "                        llm_response_complete += response\n",
    "\n",
    "                    print()\n",
    "\n",
    "                else:\n",
    "                    retrieved_docs = [c for c in collections.find({\"title\": title_note}, {\"_id\": 0})]\n",
    "\n",
    "                    if len(retrieved_docs) == 1:\n",
    "                        title_note = retrieved_docs[-1][\"title\"]\n",
    "                        content_note = retrieved_docs[-1][\"content\"]\n",
    "\n",
    "                        feedback_db =  {\"role\": \"system\", \"content\": str({\"sender\": \"Database Agent\", \"retreived_titles\": title_note, \"retrieved_content\": content_note})}\n",
    "                        message_history.append(feedback_db)\n",
    "\n",
    "                        print(\"======================System Message============================\")\n",
    "                        print(\"Sending back to main agent...\")\n",
    "                        print(\"========================AI MESSAGE==============================\")\n",
    "\n",
    "                        llm_response_complete = \"\"\n",
    "                        for chunk in client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=temperature, stream=True, messages=message_history):\n",
    "\n",
    "                            response = chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "                            print(response, end=\"\", flush=True)\n",
    "                            llm_response_complete += response\n",
    "\n",
    "                        print()\n",
    "\n",
    "            elif db_agent_resp.get('task').lower().strip() == \"delete\":\n",
    "                title_note = db_agent_resp.get('title').strip()\n",
    "                status_deletion = collections.find_one_and_delete({\"title\": title_note}, {\"_id\": 0})\n",
    "\n",
    "                if status_deletion:\n",
    "\n",
    "                    feedback_db =  {\"role\": \"system\", \"content\": str({\"sender\": \"Database Agent\", \"deleted_notes\": status_deletion.get(\"title\")})}\n",
    "                    message_history.append(feedback_db)\n",
    "\n",
    "                    print(\"======================System Message============================\")\n",
    "                    print(\"Sending back to main agent...\")\n",
    "                    print(\"========================AI MESSAGE==============================\")\n",
    "\n",
    "                    llm_response_complete = \"\"\n",
    "                    for chunk in client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=temperature, stream=True, messages=message_history):\n",
    "\n",
    "                        response = chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "                        print(response, end=\"\", flush=True)\n",
    "                        llm_response_complete += response\n",
    "\n",
    "                    print()\n",
    "\n",
    "                else:\n",
    "\n",
    "                    feedback_db =  {\"role\": \"system\", \"content\": str({\"sender\": \"Database Agent\", \"deleted_notes\": \"No note exists in database (check again)\"})}\n",
    "                    message_history.append(feedback_db)\n",
    "\n",
    "                    print(\"======================System Message============================\")\n",
    "                    print(\"Sending back to main agent...\")\n",
    "                    print(\"========================AI MESSAGE==============================\")\n",
    "\n",
    "                    llm_response_complete = \"\"\n",
    "                    for chunk in client.chat.completions.create(model=model, max_tokens=max_tokens, temperature=temperature, stream=True, messages=message_history):\n",
    "\n",
    "                        response = chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "                        print(response, end=\"\", flush=True)\n",
    "                        llm_response_complete += response\n",
    "\n",
    "                    print()\n",
    "                                    \n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
